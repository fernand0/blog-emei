---
layout: post
title:  "La inteligencia artificial y algunos argumentos alrededor de ella"
date: 2024-09-09:T09:00
---
<a data-flickr-embed="true" href="https://www.flickr.com/photos/fernand0/53916032723/in/dateposted/" title="Decoración galería comercial"><img src="https://live.staticflickr.com/65535/53916032723_1e253c4fcd_z.jpg" width="640" height="427" alt="Decoración galería comercial"/></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script>

Me gustó escuchar la intervención de Simon Willison en la PyCon US sobre inteligencia artificial. Ha puesto a disposición del que quiera verlo una transcripción con imágenes que creo que puede ser muy interesante: <a href="https://simonwillison.net/2024/Jul/14/pycon/">Imitation Intelligence, my keynote for PyCon US 2024</a>. Se puede escuchar/ver en <a href="https://youtu.be/P1-KQZZarpc">Keynote Speaker - Simon Willison</a>.

Empieza desde los oríenes de la IA (eso me gusta) allá por el año 1956 (desde que tenemos computadoras hay gente pensando en que podrían pensar) y reformula el término de inteligencia articial de los modelos grandes de lenguaje (LLMs) como inteligencia emulada.
Y no para despreciarla, sino para poder trabajar a partir de ese concepto.

<blockquote>
When discussing Large Language Models, I think a better term than “Artificial Intelligence” is “Imitation Intelligence”.

It turns out if you imitate what intelligence looks like closely enough, you can do really useful and interesting things.
</blockquote>

Pero sin olvidar que no son inteligentes, sino que simplemente imitan lo que se les ha mostrado previamente.

<blockquote>
It’s crucial to remember that these things, no matter how convincing they are when you interact with them, they are not planning and solving puzzles... and they are not intelligent entities. They’re just doing an imitation of what they’ve seen before.
</blockquote>

Habla un poco de los diversos aspectos que pueden preocuparnos de la IA (licencias, sesgos, las preguntas -<em>prompts</em>- y sus riesgos de seguridad, da algún ejemplo ...

Finalmente, hace otra reformulación cambiando lo de inteligencia artificial generativa en inteligencia artificial transformativa, porque considera que la aplicación más interesante es justamente esa: proporcionar grandes cantidades de texto y utilizarlo para evluar y hacer cosas con ello.

<blockquote>
I think the most interesting applications of this stuff when you feed large amounts of text into it, and then use it to evaluate and do things based on that input.
</blockquote>

Termina hablando de ética, desde la procedencia de los datos de entrenamiento (que no le preocupa demasiado) pero también cómo se utiliza para generar contenidos y, si estamos en ese lado, la pregunta sería si estamos generando algo valioso con la IA o simplemente aumentando el contenido automáticamente sin proporcionar nada de valor. Esto es, ¿la usamos de manera responsable?

<blockquote>
I love this term. As a practitioner, this gives me a mental model where I can think, OK, is the thing I’m doing-is it just slop? Am I just adding unwanted AI-generated junk to the world? Or am I using these tools in a responsible way?
</blockquote>

También habla del fraude (<em>cheating</em>), en particular entre los estudiantes. Nos dice: es malo porque les hace daño (si eres un estudiante y estás usando estas herramientas para que parezca que sabes algo que realmente no sabes, eso es un problema) y, además, es malo porque les puede estar dando una ventaja frente a otros.

<blockquote>
I think there are two reasons. Firstly, it hurts them. If you’re a student who cheats and you don’t learn anything, that’s set you back. Secondly, it gives them an unfair advantage over other students. So when I’m using this stuff, I try and bear that in mind.
</blockquote>

También habla de compartir las preguntas (al estilo de compartir código) y lo interesante que son estas herramientas a la hora de programar (es un foro de programadores, al fin y al cabo) por la sencilla razón de que la sintáxis y la gramática de los programas es muchísimo más simple que la de los lenguajes naturales y eso hace que funcionen bastante bien.

<blockquote>
It turns out language models are better at generating computer code than they are at generating prose in human languages, which kind of makes sense if you think about it. The grammar rules of English and Chinese are monumentally more complicated than the grammar rules of Python or JavaScript.
</blockquote>

Y se pregunta si habremos llegado al punto donde no es necesario ser un ingeniero para automatizar tareas aburridas.

<blockquote>
This offends me. You shouldn’t need a computer science degree to automate tedious tasks in your life with a computer.
</blockquote>

Pero esto también es una responsabilidad: que nadie se quede atrás, que tenemos que ayudar a otros a aprender, comprender y manejarse razonablemente en este nuevo mundo.

<blockquote>
I think that means we have a responsibility not to leave anyone behind, to help pull other people up, to understand the stuff and be able to explain it and help people navigate through these weird (and slightly dystopian at times) waters.
</blockquote>

Muy interesante.

Willison es un viejo conocido por aquí, aunque veo que no lo he enlazado apenas. Por ejemplo, en 2008, <a href="https://fernand0.blogalia.com/historias/60125">Sitios para visitar en Londres (para geeks)</a>.

